{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca21a41f-3ba5-422f-bb27-decb86aa74ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1.3911941e+000  2.4867570e-005  9.4800498e-001  2.0621103e+000  \\\n",
      "0        1.111800        0.000020        0.931299        1.847535   \n",
      "1        0.888517        0.000016        0.916051        1.665100   \n",
      "2        0.710075        0.000016        0.901771        1.508772   \n",
      "3        0.567471        0.000016        0.888154        1.373805   \n",
      "4        0.453505        0.000016        0.875008        1.256457   \n",
      "\n",
      "   9.1807675e-002  2.5920308e-002  1.2164798e+000  8.3430861e+000  \n",
      "0        0.090284        0.017671        1.181045        8.253957  \n",
      "1        0.088796        0.012010        1.146325        8.165857  \n",
      "2        0.087342        0.008140        1.112309        8.078732  \n",
      "3        0.085918        0.005503        1.078984        7.992552  \n",
      "4        0.084523        0.003712        1.046337        7.907297  \n",
      "   1.9539000e+000\n",
      "0          1.9256\n",
      "1          1.8972\n",
      "2          1.8689\n",
      "3          1.8406\n",
      "4          1.8406\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data.txt', delim_whitespace=True)\n",
    "y_data = pd.read_csv('Y.txt', delim_whitespace=True)  # assuming Y.txt has a similar format\n",
    "print(data.head())\n",
    "print(y_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cafb8a1c-b0bb-469a-9b02-89044ba4c990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of simulation data: 13149\n",
      "Length of observation data: 13149\n"
     ]
    }
   ],
   "source": [
    "# Check the length of both datasets to ensure they align\n",
    "print(\"Length of simulation data:\", len(data))\n",
    "print(\"Length of observation data:\", len(y_data))\n",
    "\n",
    "\n",
    "calibration_data = data.iloc[:3000, :]\n",
    "evaluation_data = data.iloc[3000:, :]\n",
    "calibration_obs = y_data.iloc[:3000, :]\n",
    "evaluation_obs = y_data.iloc[3000:, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8362e34e-0075-40c0-a00c-e56295d11483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration RMSE for each model: [31.405220753998154, 19.018637623421213, 18.83273796299311, 17.498699539304706, 26.0298864318581, 20.01389052179046, 19.030473465568054, 16.273959980856745]\n",
      "Evaluation RMSE for each model: [50.39485633879129, 25.26210165919862, 28.721305647598417, 27.481983615786966, 42.17904136428525, 32.87489142938715, 31.011413522564016, 21.95681607952398]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Function to calculate RMSE for each model\n",
    "def calculate_rmse(model_outputs, observed_data):\n",
    "    rmse_scores = []\n",
    "    for column in model_outputs.columns:\n",
    "        rmse = sqrt(mean_squared_error(observed_data, model_outputs[column]))\n",
    "        rmse_scores.append(rmse)\n",
    "    return rmse_scores\n",
    "\n",
    "# Calculate RMSE for calibration and evaluation phases\n",
    "rmse_cal = calculate_rmse(calibration_data, calibration_obs)\n",
    "rmse_eval = calculate_rmse(evaluation_data, evaluation_obs)\n",
    "\n",
    "print(\"Calibration RMSE for each model:\", rmse_cal)\n",
    "print(\"Evaluation RMSE for each model:\", rmse_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2075f-b8c2-4112-9551-b55bb2b6bca2",
   "metadata": {},
   "source": [
    "<p><span style=\"font-size: 18pt;\"><strong>#2.4 Equal Weights Averaging (EWA)</strong></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd6391c-4d7f-4f12-af6b-4b5f263b3a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration RMSE for EWA: 17.902309918682075\n",
      "Evaluation RMSE for EWA: 26.789392484119954\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "calibration_data = data.iloc[:3000, :]\n",
    "evaluation_data = data.iloc[3000:, :]\n",
    "calibration_obs = y_data.iloc[:3000]\n",
    "evaluation_obs = y_data.iloc[3000:]\n",
    "\n",
    "# Compute the averaged model output (Equal Weights Averaging)\n",
    "average_model_output_cal = calibration_data.mean(axis=1)\n",
    "average_model_output_eval = evaluation_data.mean(axis=1)\n",
    "\n",
    "# Calculate RMSE for the averaged model output\n",
    "calibration_rmse = sqrt(mean_squared_error(calibration_obs, average_model_output_cal))\n",
    "evaluation_rmse = sqrt(mean_squared_error(evaluation_obs, average_model_output_eval))\n",
    "\n",
    "print(\"Calibration RMSE for EWA:\", calibration_rmse)\n",
    "print(\"Evaluation RMSE for EWA:\", evaluation_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e5177b-85a4-4800-954f-f8b06f644044",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# 2.4 #############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8260f-3c2c-4a54-b36f-7294fb5e842a",
   "metadata": {},
   "source": [
    "<p><span style=\"font-size: 18pt;\"><strong>#2.4 Bates-Granger model averaging method</strong></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45cab74b-39c1-48f0-b420-e825873d6e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variances: [986.2878906073563, 361.7085770510129, 354.6720191827619, 306.2044855668628, 677.5549876554303, 400.555813818214, 362.15892032368976, 264.8417734585269]\n"
     ]
    }
   ],
   "source": [
    "#2.4 Bates-Granger model averaging method\n",
    "import numpy as np\n",
    "\n",
    "# Calculate variance of residuals for each model\n",
    "variances = []\n",
    "for i in range(calibration_data.shape[1]):  # Iterate over each model column\n",
    "    residuals = calibration_data.iloc[:, i] - calibration_obs.iloc[:, 0]\n",
    "    variance = np.mean(residuals**2)\n",
    "    variances.append(variance)\n",
    "\n",
    "# Print calculated variances for verification\n",
    "print(\"Variances:\", variances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "468df845-5aff-4f88-b2ee-057cba13e77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration RMSEs: [31.405220753998154, 19.018637623421213, 18.83273796299311, 17.498699539304706, 26.0298864318581, 20.01389052179046, 19.030473465568054, 16.273959980856745]\n",
      "Evaluation RMSEs: [50.39485633879129, 25.26210165919862, 28.721305647598417, 27.481983615786966, 42.17904136428525, 32.87489142938715, 31.011413522564016, 21.95681607952398]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Initialize lists to store RMSEs\n",
    "rmse_cal_list = []\n",
    "rmse_eval_list = []\n",
    "\n",
    "# Calculate RMSE for each model\n",
    "for i in range(calibration_data.shape[1]):\n",
    "    model_cal_rmse = sqrt(mean_squared_error(calibration_obs, calibration_data.iloc[:, i]))\n",
    "    model_eval_rmse = sqrt(mean_squared_error(evaluation_obs, evaluation_data.iloc[:, i]))\n",
    "    rmse_cal_list.append(model_cal_rmse)\n",
    "    rmse_eval_list.append(model_eval_rmse)\n",
    "\n",
    "# Print the RMSE values for each model\n",
    "print(\"Calibration RMSEs:\", rmse_cal_list)\n",
    "print(\"Evaluation RMSEs:\", rmse_eval_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45b5407c-912d-4db4-9628-60182f37b0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bates-Granger Weights: [0.04976614950782335, 0.13569971445492973, 0.13839194514081088, 0.1602972945705052, 0.07244246078324626, 0.12253910423578898, 0.13553097236387668, 0.18533235894301892]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Bates-Granger weights\n",
    "weights = [1 / variance for variance in variances]\n",
    "normalized_weights = [weight / sum(weights) for weight in weights]\n",
    "\n",
    "# Print normalized weights\n",
    "print(\"Bates-Granger Weights:\", normalized_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09eac5fa-2c20-4a25-9e61-6decbdba4576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BGA Calibration RMSE: 16.966986617810438\n",
      " BGA Evaluation RMSE: 24.96931610731972\n"
     ]
    }
   ],
   "source": [
    "# Weighted average of model outputs\n",
    "weighted_average_cal = np.sum(calibration_data * normalized_weights, axis=1)\n",
    "weighted_average_eval = np.sum(evaluation_data * normalized_weights, axis=1)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Calculate RMSE for the weighted averages\n",
    "rmse_cal = sqrt(mean_squared_error(calibration_obs, weighted_average_cal))\n",
    "rmse_eval = sqrt(mean_squared_error(evaluation_obs, weighted_average_eval))\n",
    "\n",
    "# Print RMSE results\n",
    "print(\" BGA Calibration RMSE:\", rmse_cal)\n",
    "print(\" BGA Evaluation RMSE:\", rmse_eval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b44283-24ef-4026-9975-55a0fb6c6ea3",
   "metadata": {},
   "source": [
    "<p><span style=\"font-size: 18pt;\"><strong>#2.4 Information Criterion Averaging (ICA)<br /><br /></strong></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ae3918b-669f-4e1b-b388-2ce6045620e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration RMSE AIC: 16.199021015538243\n",
      "Evaluation RMSE AIC: 21.729613891266805\n",
      "Calibration RMSE BIC: 16.199021015538243\n",
      "Evaluation RMSE BIC: 21.729613891266805\n",
      "[0.00000000e+000 1.62860541e-197 1.32843374e-188 1.31739391e-098\n",
      " 0.00000000e+000 2.37747933e-272 2.70478861e-206 1.00000000e+000]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Split the data for calibration and evaluation\n",
    "calibration_data = data.iloc[:3000, :]\n",
    "evaluation_data = data.iloc[3000:, :]\n",
    "calibration_obs = y_data.iloc[:3000]\n",
    "evaluation_obs = y_data.iloc[3000:]\n",
    "\n",
    "# Lists to store models, AICs, BICs, and predictions\n",
    "models = []\n",
    "AICs = []\n",
    "BICs = []\n",
    "calibration_predictions = []\n",
    "evaluation_predictions = []\n",
    "\n",
    "# \n",
    "for col in calibration_data.columns:\n",
    "    # Add constant to include intercept\n",
    "    X_cal = sm.add_constant(calibration_data[col])\n",
    "    X_eval = sm.add_constant(evaluation_data[col])\n",
    "\n",
    "    # Fit model on calibration data\n",
    "    model = sm.OLS(calibration_obs, X_cal).fit()\n",
    "    models.append(model)\n",
    "    AICs.append(model.aic)\n",
    "    BICs.append(model.bic)\n",
    "\n",
    "    # Predict on calibration and evaluation data\n",
    "    calibration_predictions.append(model.predict(X_cal))\n",
    "    evaluation_predictions.append(model.predict(X_eval))\n",
    "\n",
    "# Convert AICs and BICs to weights\n",
    "min_aic = min(AICs)\n",
    "min_bic = min(BICs)\n",
    "weights_aic = np.exp(-(np.array(AICs) - min_aic) / 2)\n",
    "weights_bic = np.exp(-(np.array(BICs) - min_bic) / 2)\n",
    "weights_aic /= weights_aic.sum()\n",
    "weights_bic /= weights_bic.sum()\n",
    "\n",
    "# Compute weighted averages of predictions\n",
    "weighted_avg_cal_aic = np.average(calibration_predictions, weights=weights_aic, axis=0)\n",
    "weighted_avg_eval_aic = np.average(evaluation_predictions, weights=weights_aic, axis=0)\n",
    "weighted_avg_cal_bic = np.average(calibration_predictions, weights=weights_bic, axis=0)\n",
    "weighted_avg_eval_bic = np.average(evaluation_predictions, weights=weights_bic, axis=0)\n",
    "\n",
    "# Calculate RMSE for calibration and evaluation\n",
    "rmse_cal_aic = sqrt(mean_squared_error(calibration_obs, weighted_avg_cal_aic))\n",
    "rmse_eval_aic = sqrt(mean_squared_error(evaluation_obs, weighted_avg_eval_aic))\n",
    "rmse_cal_bic = sqrt(mean_squared_error(calibration_obs, weighted_avg_cal_bic))\n",
    "rmse_eval_bic = sqrt(mean_squared_error(evaluation_obs, weighted_avg_eval_bic))\n",
    "\n",
    "# Output results\n",
    "print(\"Calibration RMSE AIC:\", rmse_cal_aic)\n",
    "print(\"Evaluation RMSE AIC:\", rmse_eval_aic)\n",
    "print(\"Calibration RMSE BIC:\", rmse_cal_bic)\n",
    "print(\"Evaluation RMSE BIC:\", rmse_eval_bic)\n",
    "print(weights_aic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f74d67a-5690-4ed8-a36a-8bac2bd85f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC Weights (Betas):\n",
      "Beta_1: 0.0000\n",
      "Beta_2: 0.0000\n",
      "Beta_3: 0.0000\n",
      "Beta_4: 0.0000\n",
      "Beta_5: 0.0000\n",
      "Beta_6: 0.0000\n",
      "Beta_7: 0.0000\n",
      "Beta_8: 1.0000\n",
      "\n",
      "Calibration RMSE: 16.315458052956362\n",
      "Evaluation RMSE: 21.594831189824628\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Fit models for the entire dataset, one per column\n",
    "models = []\n",
    "AICs = []\n",
    "for col in data.columns:\n",
    "    X = sm.add_constant(data[[col]])  \n",
    "    model = sm.OLS(y_data, X).fit()\n",
    "    models.append(model)\n",
    "    AICs.append(model.aic)\n",
    "\n",
    "# Calculate weights from AIC\n",
    "min_aic = min(AICs)\n",
    "weights_aic = np.exp(-(np.array(AICs) - min_aic) / 2)\n",
    "weights_aic /= weights_aic.sum()\n",
    "\n",
    "# Output the AIC weights\n",
    "print(\"AIC Weights (Betas):\")\n",
    "for idx, weight in enumerate(weights_aic, 1):\n",
    "    print(f\"Beta_{idx}: {weight:.4f}\")\n",
    "\n",
    "# Prepare predictions using the correct subsets of data\n",
    "full_predictions = [m.predict(sm.add_constant(data[[data.columns[i]]])) for i, m in enumerate(models)]\n",
    "\n",
    "# Now handle the calibration and evaluation data separately\n",
    "calibration_predictions = np.column_stack([p[:3000] for p in full_predictions])\n",
    "evaluation_predictions = np.column_stack([p[3000:] for p in full_predictions])\n",
    "\n",
    "# Compute weighted averages\n",
    "weighted_avg_cal = np.average(calibration_predictions, weights=weights_aic, axis=1)\n",
    "weighted_avg_eval = np.average(evaluation_predictions, weights=weights_aic, axis=1)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_cal = sqrt(mean_squared_error(y_data.iloc[:3000], weighted_avg_cal))\n",
    "rmse_eval = sqrt(mean_squared_error(y_data.iloc[3000:], weighted_avg_eval))\n",
    "\n",
    "# Print RMSE results\n",
    "print(\"\\nCalibration RMSE:\", rmse_cal)\n",
    "print(\"Evaluation RMSE:\", rmse_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "434fbfdd-6c76-48fa-8e16-e85885f3d109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIC Weights (Betas):\n",
      "Beta_1: 0.0000\n",
      "Beta_2: 0.0000\n",
      "Beta_3: 0.0000\n",
      "Beta_4: 0.0000\n",
      "Beta_5: 0.0000\n",
      "Beta_6: 0.0000\n",
      "Beta_7: 0.0000\n",
      "Beta_8: 1.0000\n",
      "\n",
      "Calibration RMSE: 16.315458052956362\n",
      "Evaluation RMSE: 21.594831189824628\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "\n",
    "# Fit models for the entire dataset, one per column\n",
    "models = []\n",
    "BICs = []\n",
    "for col in data.columns:\n",
    "    X = sm.add_constant(data[[col]])  \n",
    "    model = sm.OLS(y_data, X).fit()\n",
    "    models.append(model)\n",
    "    BICs.append(model.bic)\n",
    "\n",
    "# Calculate weights from BIC\n",
    "min_bic = min(BICs)\n",
    "weights_bic = np.exp(-(np.array(BICs) - min_bic) / 2)\n",
    "weights_bic /= weights_bic.sum()\n",
    "\n",
    "# Output the BIC weights\n",
    "print(\"BIC Weights (Betas):\")\n",
    "for idx, weight in enumerate(weights_bic, 1):\n",
    "    print(f\"Beta_{idx}: {weight:.4f}\")\n",
    "\n",
    "# Prepare predictions using the correct subsets of data\n",
    "full_predictions = [m.predict(sm.add_constant(data[[data.columns[i]]])) for i, m in enumerate(models)]\n",
    "\n",
    "# Now handle the calibration and evaluation data separately\n",
    "calibration_predictions = np.column_stack([p[:3000] for p in full_predictions])\n",
    "evaluation_predictions = np.column_stack([p[3000:] for p in full_predictions])\n",
    "\n",
    "# Compute weighted averages\n",
    "weighted_avg_cal = np.average(calibration_predictions, weights=weights_bic, axis=1)\n",
    "weighted_avg_eval = np.average(evaluation_predictions, weights=weights_bic, axis=1)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_cal = sqrt(mean_squared_error(y_data.iloc[:3000], weighted_avg_cal))\n",
    "rmse_eval = sqrt(mean_squared_error(y_data.iloc[3000:], weighted_avg_eval))\n",
    "\n",
    "# Print RMSE results\n",
    "print(\"\\nCalibration RMSE:\", rmse_cal)\n",
    "print(\"Evaluation RMSE:\", rmse_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4f985c-5625-4d99-b371-7c4a896449d7",
   "metadata": {},
   "source": [
    "<p><span style=\"font-size: 18pt;\"><strong>Granger-Ramanathan averaging</strong></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db1dda37-0eb1-48f4-924e-462c5bc56281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRA Weights (Betas):\n",
      "Beta_1: -0.0367\n",
      "Beta_2: 0.2473\n",
      "Beta_3: 0.0959\n",
      "Beta_4: 0.2764\n",
      "Beta_5: -0.0953\n",
      "Beta_6: -0.1930\n",
      "Beta_7: -0.0269\n",
      "Beta_8: 0.7093\n",
      "\n",
      "Calibration RMSE: 15.708349089078702\n",
      "Evaluation RMSE: 20.29853756594686\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Fit models for the entire dataset, one per column\n",
    "models = []\n",
    "predictions = []\n",
    "\n",
    "for col in data.columns:\n",
    "    X = sm.add_constant(data[[col]])  \n",
    "    model = sm.OLS(y_data, X).fit()\n",
    "    models.append(model)\n",
    "    predictions.append(model.predict(X))\n",
    "\n",
    "# Convert predictions to a matrix (Y)\n",
    "Y = np.column_stack(predictions)\n",
    "\n",
    "# Fit the OLS model to find betas (weights)\n",
    "X = sm.add_constant(Y)\n",
    "ols_model = sm.OLS(y_data, X).fit()\n",
    "betas = ols_model.params[1:]  # exclude the intercept\n",
    "\n",
    "# Print the GRA weights (betas)\n",
    "print(\"GRA Weights (Betas):\")\n",
    "for idx, beta in enumerate(betas, 1):\n",
    "    print(f\"Beta_{idx}: {beta:.4f}\")\n",
    "\n",
    "# Prepare weighted predictions using the betas\n",
    "weighted_predictions = np.dot(Y, betas)\n",
    "\n",
    "# Split the data for calibration and evaluation\n",
    "calibration_data = data.iloc[:3000, :]\n",
    "evaluation_data = data.iloc[3000:, :]\n",
    "calibration_obs = y_data.iloc[:3000]\n",
    "evaluation_obs = y_data.iloc[3000:]\n",
    "\n",
    "# Compute weighted averages for calibration and evaluation\n",
    "calibration_predictions = weighted_predictions[:3000]\n",
    "evaluation_predictions = weighted_predictions[3000:]\n",
    "\n",
    "# Calculate RMSE for calibration and evaluation\n",
    "rmse_cal = sqrt(mean_squared_error(calibration_obs, calibration_predictions))\n",
    "rmse_eval = sqrt(mean_squared_error(evaluation_obs, evaluation_predictions))\n",
    "\n",
    "# Print RMSE results\n",
    "print(\"\\nCalibration RMSE:\", rmse_cal)\n",
    "print(\"Evaluation RMSE:\", rmse_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5b691b-de0b-4d0f-9a09-9a2d218a990e",
   "metadata": {},
   "source": [
    "<p><span style=\"font-size: 18pt;\"><strong>Mallows Model Averaging (MMA)</strong></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40b09b21-0811-498d-bc6e-639213b3d297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:504: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "/home/jovyan/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:231: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMA Weights (Betas):\n",
      "Beta_1: 0.6353\n",
      "Beta_2: 0.0000\n",
      "Beta_3: 0.0000\n",
      "Beta_4: 0.0000\n",
      "Beta_5: 0.3647\n",
      "Beta_6: 0.0000\n",
      "Beta_7: 0.0000\n",
      "Beta_8: 0.0000\n",
      "\n",
      "Calibration RMSE: 26.362207397556055\n",
      "Evaluation RMSE: 39.84748976888232\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "\n",
    "# Fit models for the entire dataset, one per column\n",
    "models = []\n",
    "predictions = []\n",
    "p_k = []\n",
    "\n",
    "for col in data.columns:\n",
    "    X = sm.add_constant(data[[col]])  \n",
    "    model = sm.OLS(y_data, X).fit()\n",
    "    models.append(model)\n",
    "    predictions.append(model.predict(X))\n",
    "    p_k.append(len(model.params))  # Number of parameters for each model\n",
    "\n",
    "# Convert predictions to a matrix (Y in the formula)\n",
    "Y = np.column_stack(predictions)\n",
    "\n",
    "# Ensure y_data is a numpy array\n",
    "y_data_np = y_data.to_numpy()\n",
    "\n",
    "# Define the objective function C_K(beta) as described\n",
    "def CK(beta, Y, y, p_k, S2):\n",
    "    residuals = y - np.dot(Y, beta)\n",
    "    penalty = 2 * S2 * np.dot(beta, p_k)\n",
    "    return np.sum(residuals**2) + penalty\n",
    "\n",
    "# Estimate S2 (variance of the forecast error) using the model with the most parameters\n",
    "S2 = np.var(y_data_np - np.dot(Y, np.ones(len(models)) / len(models)))\n",
    "\n",
    "# Define the constraint that the weights sum to one\n",
    "constraints = ({'type': 'eq', 'fun': lambda beta: np.sum(beta) - 1})\n",
    "\n",
    "# Define the bounds to be between 0 and 1 for each beta\n",
    "bounds = [(0, 1) for _ in range(len(models))]\n",
    "\n",
    "# Set the initial guess for the weights to random values that sum to 1\n",
    "np.random.seed(0)  # For reproducibility\n",
    "initial_guess = np.random.rand(len(models))\n",
    "initial_guess /= initial_guess.sum()\n",
    "\n",
    "# Perform the optimization to find the optimal weights using a different method\n",
    "result = minimize(CK, initial_guess, args=(Y, y_data_np, p_k, S2), constraints=constraints, bounds=bounds, method='trust-constr')\n",
    "\n",
    "# Get the optimal weights (betas)\n",
    "betas = result.x\n",
    "\n",
    "# Print the MMA weights (betas)\n",
    "print(\"MMA Weights (Betas):\")\n",
    "for idx, beta in enumerate(betas, 1):\n",
    "    print(f\"Beta_{idx}: {beta:.4f}\")\n",
    "\n",
    "# Prepare weighted predictions using the betas\n",
    "weighted_predictions = np.dot(Y, betas)\n",
    "\n",
    "# Split the data for calibration and evaluation\n",
    "calibration_obs = y_data_np[:3000]\n",
    "evaluation_obs = y_data_np[3000:]\n",
    "\n",
    "# Compute weighted averages for calibration and evaluation\n",
    "calibration_predictions = weighted_predictions[:3000]\n",
    "evaluation_predictions = weighted_predictions[3000:]\n",
    "\n",
    "# Calculate RMSE for calibration and evaluation\n",
    "rmse_cal = sqrt(mean_squared_error(calibration_obs, calibration_predictions))\n",
    "rmse_eval = sqrt(mean_squared_error(evaluation_obs, evaluation_predictions))\n",
    "\n",
    "# Print RMSE results\n",
    "print(\"\\nCalibration RMSE:\", rmse_cal)\n",
    "print(\"Evaluation RMSE:\", rmse_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7d7329a-8b5b-4674-8909-34e8d4c6ef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:504: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "/home/jovyan/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:231: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMA Weights (Betas) with S^K=1:\n",
      "Beta_1: 0.6353\n",
      "Beta_2: 0.0000\n",
      "Beta_3: 0.0000\n",
      "Beta_4: 0.0000\n",
      "Beta_5: 0.3647\n",
      "Beta_6: 0.0000\n",
      "Beta_7: 0.0000\n",
      "Beta_8: 0.0000\n",
      "\n",
      "Calibration RMSE: 26.362207397556055\n",
      "Evaluation RMSE: 39.84748976888232\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "models = []\n",
    "predictions = []\n",
    "p_k = []\n",
    "\n",
    "for col in data.columns:\n",
    "    X = sm.add_constant(data[[col]])  \n",
    "    model = sm.OLS(y_data, X).fit()\n",
    "    models.append(model)\n",
    "    predictions.append(model.predict(X))\n",
    "    p_k.append(len(model.params))  # Number of parameters for each model\n",
    "\n",
    "# Convert predictions to a matrix (Y in the formula)\n",
    "Y = np.column_stack(predictions)\n",
    "\n",
    "# Ensure y_data is a numpy array\n",
    "y_data_np = y_data.to_numpy()\n",
    "\n",
    "# Define the objective function C_K(beta) as described\n",
    "def CK(beta, Y, y, p_k, S2):\n",
    "    residuals = y - np.dot(Y, beta)\n",
    "    penalty = 2 * S2 * np.dot(beta, p_k)\n",
    "    return np.sum(residuals**2) + penalty\n",
    "\n",
    "# Estimate S2 (variance of the forecast error) using the model with the most parameters\n",
    "S2 = np.var(y_data_np - np.dot(Y, np.ones(len(models)) / len(models)))\n",
    "\n",
    "# Define the constraint that the weights sum to one\n",
    "constraints = ({'type': 'eq', 'fun': lambda beta: np.sum(beta) - 1})\n",
    "\n",
    "# Define the bounds to be between 0 and 1 for each beta\n",
    "bounds = [(0, 1) for _ in range(len(models))]\n",
    "\n",
    "# Set the initial guess for the weights to random values that sum to 1\n",
    "np.random.seed(0)  # For reproducibility\n",
    "initial_guess = np.random.rand(len(models))\n",
    "initial_guess /= initial_guess.sum()\n",
    "\n",
    "# Perform the optimization to find the optimal weights using a different method\n",
    "result = minimize(CK, initial_guess, args=(Y, y_data_np, p_k, S2), constraints=constraints, bounds=bounds, method='trust-constr')\n",
    "\n",
    "# Get the optimal weights (betas)\n",
    "betas = result.x\n",
    "\n",
    "# Print the MMA weights (betas)\n",
    "print(\"MMA Weights (Betas) with S^K=1:\")\n",
    "for idx, beta in enumerate(betas, 1):\n",
    "    print(f\"Beta_{idx}: {beta:.4f}\")\n",
    "\n",
    "# Prepare weighted predictions using the betas\n",
    "weighted_predictions = np.dot(Y, betas)\n",
    "\n",
    "# Split the data for calibration and evaluation\n",
    "calibration_obs = y_data_np[:3000]\n",
    "evaluation_obs = y_data_np[3000:]\n",
    "\n",
    "# Compute weighted averages for calibration and evaluation\n",
    "calibration_predictions = weighted_predictions[:3000]\n",
    "evaluation_predictions = weighted_predictions[3000:]\n",
    "\n",
    "# Calculate RMSE for calibration and evaluation\n",
    "rmse_cal = sqrt(mean_squared_error(calibration_obs, calibration_predictions))\n",
    "rmse_eval = sqrt(mean_squared_error(evaluation_obs, evaluation_predictions))\n",
    "\n",
    "# Print RMSE results\n",
    "print(\"\\nCalibration RMSE:\", rmse_cal)\n",
    "print(\"Evaluation RMSE:\", rmse_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "961d4f27-ff61-43a9-8c31-672a567e6c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MMA Weights (Betas) with S^K=0:\n",
      "Beta_1: 0.3209\n",
      "Beta_2: 0.3146\n",
      "Beta_3: -0.1832\n",
      "Beta_4: -0.1744\n",
      "Beta_5: 0.4205\n",
      "Beta_6: -0.1441\n",
      "Beta_7: 0.3207\n",
      "Beta_8: -0.4843\n",
      "\n",
      "Calibration RMSE without constraints: 39.31996445912326\n",
      "Evaluation RMSE without constraints: 64.8128086266838\n"
     ]
    }
   ],
   "source": [
    "# Perform the optimization to find the optimal weights without the constraint\n",
    "result_no_constraint = minimize(CK, initial_guess, args=(Y, y_data_np, p_k, S2), method='trust-constr')\n",
    "\n",
    "# Get the optimal weights (betas) without constraints\n",
    "betas_no_constraint = result_no_constraint.x\n",
    "\n",
    "# Print the MMA weights (betas)\n",
    "print(\"\\nMMA Weights (Betas) with S^K=0:\")\n",
    "for idx, beta in enumerate(betas_no_constraint, 1):\n",
    "    print(f\"Beta_{idx}: {beta:.4f}\")\n",
    "\n",
    "# Prepare weighted predictions using the betas without constraints\n",
    "weighted_predictions_no_constraint = np.dot(Y, betas_no_constraint)\n",
    "\n",
    "# Compute weighted averages for calibration and evaluation without constraints\n",
    "calibration_predictions_no_constraint = weighted_predictions_no_constraint[:3000]\n",
    "evaluation_predictions_no_constraint = weighted_predictions_no_constraint[3000:]\n",
    "\n",
    "# Calculate RMSE for calibration and evaluation without constraints\n",
    "rmse_cal_no_constraint = sqrt(mean_squared_error(calibration_obs, calibration_predictions_no_constraint))\n",
    "rmse_eval_no_constraint = sqrt(mean_squared_error(evaluation_obs, evaluation_predictions_no_constraint))\n",
    "\n",
    "# Print RMSE results without constraints\n",
    "print(\"\\nCalibration RMSE without constraints:\", rmse_cal_no_constraint)\n",
    "print(\"Evaluation RMSE without constraints:\", rmse_eval_no_constraint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056efd4f-32a5-4094-99f4-e6fecbb8efe6",
   "metadata": {},
   "source": [
    "<p><span style=\"font-size: 18pt;\"><strong>Basyn Model Avergaing&nbsp;</strong></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "502d4bb9-ef02-41dc-97b1-9b4368942eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "# Log liklihood \n",
    "def log_likelihood(theta, Y, y):\n",
    "    K = Y.shape[1]\n",
    "    betas = theta[:K]\n",
    "    sigmas = theta[K:2*K]\n",
    "    n = len(y)\n",
    "    \n",
    "    # Compute  log-likelihood\n",
    "    log_lik = 0\n",
    "    for t in range(n):\n",
    "        pred_density = 0\n",
    "        for k in range(K):\n",
    "            pred_density += betas[k] * norm.pdf(y[t], loc=Y[t, k], scale=sigmas[k])\n",
    "        log_lik += np.log(pred_density)\n",
    "    \n",
    "    return -log_lik  # Return negative log-likelihood for minimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4270f94e-7497-432a-82c1-95ee07428621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models for the entire dataset, one per column\n",
    "models = []\n",
    "predictions = []\n",
    "p_k = []\n",
    "\n",
    "for col in data.columns:\n",
    "    X = sm.add_constant(data[[col]])  # Use double brackets to ensure DataFrame format\n",
    "    model = sm.OLS(y_data, X).fit()\n",
    "    models.append(model)\n",
    "    predictions.append(model.predict(X))\n",
    "    p_k.append(len(model.params))  \n",
    "\n",
    "# Convert predictions to a matrix (Y in the formula)\n",
    "Y = np.column_stack(predictions)\n",
    "\n",
    "# Ensure y_data is a numpy array\n",
    "y_data_np = y_data.to_numpy()\n",
    "\n",
    "# Set the initial values for theta\n",
    "K = len(models)\n",
    "initial_betas = np.ones(K) / K\n",
    "initial_sigmas = np.std(Y, axis=0) * 5\n",
    "initial_theta = np.concatenate([initial_betas, initial_sigmas])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "319704b4-c03b-4e21-a000-d5ec484e9743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py:1988: RuntimeWarning: divide by zero encountered in divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n"
     ]
    }
   ],
   "source": [
    "# Define the bounds for DE-MC\n",
    "bounds = [(0, 1)] * K + [(0, 5 * np.std(y_data_np))] * K\n",
    "\n",
    "# Normalize function\n",
    "def normalize_theta(theta):\n",
    "    K = len(theta) // 2\n",
    "    betas = theta[:K]\n",
    "    normalized_betas = betas / np.sum(betas)\n",
    "    return np.concatenate([normalized_betas, theta[K:]])\n",
    "\n",
    "# DE-MC optimization\n",
    "def demc_optimization(Y, y, bounds, iterations=10000, popsize=15):\n",
    "    # Initialize population\n",
    "    population = []\n",
    "    for _ in range(popsize):\n",
    "        theta = np.random.uniform(low=[b[0] for b in bounds], high=[b[1] for b in bounds])\n",
    "        theta = normalize_theta(theta)\n",
    "        population.append(theta)\n",
    "    \n",
    "    population = np.array(population)\n",
    "    \n",
    "    # Main DE-MC loop\n",
    "    for iter in range(iterations):\n",
    "        new_population = []\n",
    "        for i in range(popsize):\n",
    "            indices = np.random.choice(range(popsize), 3, replace=False)\n",
    "            a, b, c = population[indices]\n",
    "            mutation = a + 0.8 * (b - c)\n",
    "            mutation = np.clip(mutation, [b[0] for b in bounds], [b[1] for b in bounds])\n",
    "            mutation = normalize_theta(mutation)\n",
    "            new_population.append(mutation)\n",
    "        \n",
    "        population = np.array(new_population)\n",
    "    \n",
    "    # Find the best solution\n",
    "    best_theta = min(population, key=lambda theta: log_likelihood(theta, Y, y))\n",
    "    return best_theta\n",
    "\n",
    "# Run DE-MC optimization\n",
    "best_theta = demc_optimization(Y, y_data_np, bounds)\n",
    "betas_bma = best_theta[:K]\n",
    "sigmas_bma = best_theta[K:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a91716b-32e9-4fdd-a024-01756cae2042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMA Weights (Betas):\n",
      "Beta_1: 0.0695\n",
      "Beta_2: 0.0253\n",
      "Beta_3: 0.0000\n",
      "Beta_4: 0.0212\n",
      "Beta_5: 0.0628\n",
      "Beta_6: 0.4570\n",
      "Beta_7: 0.0008\n",
      "Beta_8: 0.3633\n",
      "\n",
      "Calibration RMSE: 17.57596825950873\n",
      "Evaluation RMSE: 26.63719861156392\n"
     ]
    }
   ],
   "source": [
    "# Print the BMA weights (betas)\n",
    "print(\"BMA Weights (Betas):\")\n",
    "for idx, beta in enumerate(betas_bma, 1):\n",
    "    print(f\"Beta_{idx}: {beta:.4f}\")\n",
    "\n",
    "# Prepare weighted predictions using the betas\n",
    "weighted_predictions_bma = np.dot(Y, betas_bma)\n",
    "\n",
    "# Split the data for calibration and evaluation\n",
    "calibration_obs = y_data_np[:3000]\n",
    "evaluation_obs = y_data_np[3000:]\n",
    "\n",
    "# Compute weighted averages for calibration and evaluation\n",
    "calibration_predictions_bma = weighted_predictions_bma[:3000]\n",
    "evaluation_predictions_bma = weighted_predictions_bma[3000:]\n",
    "\n",
    "# Calculate RMSE for calibration and evaluation\n",
    "rmse_cal_bma = sqrt(mean_squared_error(calibration_obs, calibration_predictions_bma))\n",
    "rmse_eval_bma = sqrt(mean_squared_error(evaluation_obs, evaluation_predictions_bma))\n",
    "\n",
    "# Print RMSE results\n",
    "print(\"\\nCalibration RMSE:\", rmse_cal_bma)\n",
    "print(\"Evaluation RMSE:\", rmse_eval_bma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4753980-7c48-4687-8b67-a1c5b2cb2a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
