{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f4efa5c-9c57-4073-b497-092063725f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1.3911941e+000  2.4867570e-005  9.4800498e-001  2.0621103e+000  \\\n",
      "0        1.111800        0.000020        0.931299        1.847535   \n",
      "1        0.888517        0.000016        0.916051        1.665100   \n",
      "2        0.710075        0.000016        0.901771        1.508772   \n",
      "3        0.567471        0.000016        0.888154        1.373805   \n",
      "4        0.453505        0.000016        0.875008        1.256457   \n",
      "\n",
      "   9.1807675e-002  2.5920308e-002  1.2164798e+000  8.3430861e+000  \n",
      "0        0.090284        0.017671        1.181045        8.253957  \n",
      "1        0.088796        0.012010        1.146325        8.165857  \n",
      "2        0.087342        0.008140        1.112309        8.078732  \n",
      "3        0.085918        0.005503        1.078984        7.992552  \n",
      "4        0.084523        0.003712        1.046337        7.907297  \n",
      "   1.9539000e+000\n",
      "0          1.9256\n",
      "1          1.8972\n",
      "2          1.8689\n",
      "3          1.8406\n",
      "4          1.8406\n",
      "Length of simulation data: 13149\n",
      "Length of observation data: 13149\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "data = pd.read_csv('data.txt', delim_whitespace=True)\n",
    "y_data = pd.read_csv('Y.txt', delim_whitespace=True)  t\n",
    "print(data.head())\n",
    "print(y_data.head())\n",
    "# Check the length of both datasets to ensure they align\n",
    "print(\"Length of simulation data:\", len(data))\n",
    "print(\"Length of observation data:\", len(y_data))\n",
    "\n",
    "calibration_data = data.iloc[:3000, :]\n",
    "evaluation_data = data.iloc[3000:, :]\n",
    "calibration_obs = y_data.iloc[:3000, :]\n",
    "evaluation_obs = y_data.iloc[3000:, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47624702-2381-45c2-a76e-6cac91e7d6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration RMSE for each model: [31.405220753998154, 19.018637623421213, 18.83273796299311, 17.498699539304706, 26.0298864318581, 20.01389052179046, 19.030473465568054, 16.273959980856745]\n",
      "Evaluation RMSE for each model: [50.39485633879129, 25.26210165919862, 28.721305647598417, 27.481983615786966, 42.17904136428525, 32.87489142938715, 31.011413522564016, 21.95681607952398]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to calculate RMSE for each model\n",
    "def calculate_rmse(model_outputs, observed_data):\n",
    "    rmse_scores = []\n",
    "    for column in model_outputs.columns:\n",
    "        rmse = sqrt(mean_squared_error(observed_data, model_outputs[column]))\n",
    "        rmse_scores.append(rmse)\n",
    "    return rmse_scores\n",
    "\n",
    "# Calculate RMSE for calibration and evaluation phases\n",
    "rmse_cal = calculate_rmse(calibration_data, calibration_obs)\n",
    "rmse_eval = calculate_rmse(evaluation_data, evaluation_obs)\n",
    "\n",
    "print(\"Calibration RMSE for each model:\", rmse_cal)\n",
    "print(\"Evaluation RMSE for each model:\", rmse_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e23511b-935a-442b-a8d2-a8ae1b34c604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of simulation data: 13149\n",
      "Length of observation data: 13149\n",
      "Calibration RMSE for each model: [31.41, 19.02, 18.83, 17.5, 26.03, 20.01, 19.03, 16.27]\n",
      "Evaluation RMSE for each model: [50.39, 25.26, 28.72, 27.48, 42.18, 32.87, 31.01, 21.96]\n",
      "     Model  RMSE_cal  RMSE_eval\n",
      "0      ABC     31.41      50.39\n",
      "1     GR4J     19.02      25.26\n",
      "2    HYMOD     18.83      28.72\n",
      "3    TOPMO     17.50      27.48\n",
      "4     AWBM     26.03      42.18\n",
      "5      NAM     20.01      32.87\n",
      "6      HBV     19.03      31.01\n",
      "7  SAC-SMA     16.27      21.96\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Load simulation data and observation data\n",
    "data = pd.read_csv('data.txt', delim_whitespace=True)\n",
    "y_data = pd.read_csv('Y.txt', delim_whitespace=True)  # assuming Y.txt has a similar format\n",
    "\n",
    "# Check the length of both datasets to ensure they align\n",
    "print(\"Length of simulation data:\", len(data))\n",
    "print(\"Length of observation data:\", len(y_data))\n",
    "\n",
    "calibration_data = data.iloc[:3000, :]\n",
    "evaluation_data = data.iloc[3000:, :]\n",
    "calibration_obs = y_data.iloc[:3000]\n",
    "evaluation_obs = y_data.iloc[3000:]\n",
    "\n",
    "# Function to calculate RMSE for each model\n",
    "def calculate_rmse(model_outputs, observed_data):\n",
    "    rmse_scores = []\n",
    "    for column in model_outputs.columns:\n",
    "        rmse = sqrt(mean_squared_error(observed_data, model_outputs[column]))\n",
    "        rmse_scores.append(round(rmse, 2))\n",
    "    return rmse_scores\n",
    "\n",
    "# Calculate RMSE for calibration and evaluation phases\n",
    "rmse_cal = calculate_rmse(calibration_data, calibration_obs)\n",
    "rmse_eval = calculate_rmse(evaluation_data, evaluation_obs)\n",
    "\n",
    "# Print the calibration and evaluation RMSE for each model\n",
    "print(\"Calibration RMSE for each model:\", rmse_cal)\n",
    "print(\"Evaluation RMSE for each model:\", rmse_eval)\n",
    "\n",
    "# Optionally, update the table with RMSE values\n",
    "models = ['ABC', 'GR4J', 'HYMOD', 'TOPMO', 'AWBM', 'NAM', 'HBV', 'SAC-SMA']\n",
    "result_table = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'RMSE_cal': rmse_cal,\n",
    "    'RMSE_eval': rmse_eval\n",
    "})\n",
    "print(result_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201e97e7-7b51-496b-839d-fd8615dc7bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
